\documentclass[12pt]{amsart}
\usepackage{geometry}                % See geometry.pdf to learn the layout options. There are lots.
\geometry{a4paper}                   % ... or a4paper or a5paper or ... 
%\geometry{landscape}                % Activate for for rotated page geometry
%\usepackage[parfill]{parskip}    % Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{epstopdf}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\title{molten component analysis}
\author{Ko ABE}
%\date{}                                           % Activate to display a given date or no date

\newcommand\Poissond{\mathrm{Poisson}}
\newcommand\Gammad{\mathrm{Gamma}}

\begin{document}
\maketitle

\section{Poisson distribution}
\subsection{Estimation}

Now, consider following data generating process; 
\begin{align}
y_n &\sim  \Poissond\left(\sum_{l=1}^L \prod_{d=1}^D \lambda_{dl}^{x_{nd}}, \right) \label{geney}\\
\lambda &\sim \Gammad(a, b), \nonumber
\end{align}
where $\Poissond(\lambda)$ is Poisson distribution with mean $\lambda$ and $\Gammad(a, b)$ is gamma distribution with shape $a$, and scale $b$. 

\subsection{Variational inference}
Equation \ref{geney} is equivalent to following:
\begin{align}
y_{n} &= \sum_{l=1}^{L} u_{nl},\nonumber \\
u_{nl} &\sim \Poissond\left(\prod_{d=1}^{D} \lambda_{dl}^{x_{nd}} \right)
\end{align}
Using the mean field assumption (Jordan \textit{et al}., 1999), we introduce closed-form variational Bayes inference updates for the proposal model.
Let $q(\lambda_{k,l})$ and $q(\boldsymbol{h}_{l})$ be the target approximate posterior distribution.

The updates for $u_{nl}$ are given by $E[u_{nl}] = y_{n} p_{nl}$ where $p_{nl}$ is defined as 
\begin{align}
p_{nl} =\frac{\exp( x_{nd} E[\log \lambda_{dl}] )}{ \exp(\sum_{d=1}^{D}x_{nd} E[\log \lambda_{dl}] )}
\end{align}

The mean-field posterior $q(\lambda_{dl})$ is gamma distribution with shape parameter $\hat a_{dl}$ and rate parameter $\hat b_{dl}$ where
\begin{align}
\hat a_{dl} &= \sum_{n=1}^{N}x_{nd} u_{nl} + a, \\
\hat b_{dl} &= \sum_{n=1}^{N} x_{nd} \left( \prod_{d'\neq d} \lambda_{d'l}^{x_{nd'}} \right) + b.
\end{align}

The mean-field posterior $q(\lambda_{dl})$ is gamma distribution with shape parameter $\hat a_{dl}$ and rate parameter $\hat b_{dl}$ where
\begin{align}
\hat a_{dl} &= \sum_{n=1}^{N}  x_{nd} u_{nd} + a, \\
\hat b_{dl} &= \sum_{n=1}^{N} x_{nd} \left( \prod_{d'\neq d} \lambda_{d' l}^{x_{nd'}} \right) + b.
\end{align}

Thus, $E[\lambda_{dl}] = \hat a_{dl} / \hat b_{dl}$ and $E[\lambda_{dl}] = \psi (\hat a_{dl}) - \log( \hat b_{dl})$ where $\psi(\cdot)$ is digamma function.

\subsection*{Lower bound on marginal likelihood}
Lower bound on marginal likelihood (evidence lower bound; ELBO) $\mathcal{L}(q)$ is used for model selection (Corduneanu and Bishop, 2001).

\begin{align}
\mathcal{L}(q) &= \int q(\theta) \log \frac{p(\boldsymbol{y},\theta|X,a_w, b_w, a, b)}{q(\theta)} d\theta \\
&=\int q(\theta) \log p(\boldsymbol{y},\theta|X,a_w, b_w, a, b) d\theta - \int q(\theta) \log q(\theta) d\theta \label{ELBO}.
\end{align}
where $\theta$ is all the variational parameters.

\end{document}  
